from pyspark.sql import SparkSession
from pyspark.sql.functions import col, collect_list, when
from pyspark.sql.window import Window

def add_product_list(spark, df):
    # Convert business_date and open_date columns to date type if they are in string format
    df = df.withColumn("business_date", col("business_date").cast("date"))
    df = df.withColumn("open_date", col("open_date").cast("date"))

    # Define window specification
    windowSpec = Window.partitionBy("ip_id").orderBy("business_date").rowsBetween(Window.unboundedPreceding, -1)

    # Create a column with a list of products opened before the business_date
    df = df.withColumn("products_opened_before", 
                       collect_list(when(col("open_date") < col("business_date"), col("Segmt_Prod_Type"))).over(windowSpec))

    return df

# Example usage
spark = SparkSession.builder.appName("RecommenderSystem").getOrCreate()

data = [
    (1, 'A', '2023-01-01', '2022-01-01', '2021-01-01', 1, 100.0),
    (2, 'A', '2023-01-02', '2022-01-02', '2021-01-02', 1, 200.0),
    (3, 'A', '2023-01-01', '2022-01-03', '2021-01-03', 1, 150.0),
    (1, 'B', '2023-01-01', '2022-01-01', '2021-01-01', 1, 300.0),
    (2, 'B', '2023-01-03', '2022-01-03', '2021-01-03', 1, 400.0),
    (1, 'C', '2023-01-04', '2022-01-04', '2021-01-04', 1, 500.0)
]

columns = ['ip_id', 'Segmt_Prod_Type', 'business_date', 'open_date', 'one_year_before_open_date', 'Flag', 'balance']

df = spark.createDataFrame(data, columns)

# Add the product list column
df_with_product_list = add_product_list(spark, df)

# Show the resulting DataFrame
df_with_product_list.show(truncate=False)
