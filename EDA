Cluster 0:
Balance Trend: Extremely high positive balance trend of 969,500, the highest among all clusters.
Product Holdings:
Money Market: 53.82% ownership, which is much higher compared to other clusters.
HELOC: Notably high proportion of households with HELOC accounts.
Cluster 1:
Balance Trend: Only cluster with a negative balance trend (-10,131), which is a strong differentiator.
Product Holdings:
Commercial Line of Credit: High presence in this cluster.
HELOC: High ownership compared to other clusters.
Roth IRA: Significant representation of Roth IRA accounts.
Cluster 2:
Recent Openings: Most active cluster in the last 30 days, with 3 new products opened.
Balance Trend: Positive trend of 428,006.
Product Holdings:
Private Wealth CD: High ownership.
Individual IRA: Prominent in this cluster.
Cluster 3:
Balance Trend: Moderate positive trend of 379,054, lower than Cluster 0 but still notable.
Product Holdings:
Trust Accounts: Significant proportion of Trust and Roth IRA accounts.
Private Wealth CD: High representation in this cluster.
Cluster 4:
Balances: Lower current and ledger balances, reflecting more conservative financial profiles.
Product Holdings:
Trust Accounts: Strong representation of Trust products.
Cluster 5:
Recent Product Openings: High activity in opening credit products like Credit Cards and Loans.
Product Holdings:
Prime Time Checking: Higher ownership compared to other clusters.
Cluster 6:
Balances: Very low balances and balance trends compared to other clusters, indicating low financial activity.
Product Holdings:
SEP IRA and Traditional IRA: Higher ownership, showing a focus on retirement planning.
Cluster 7:
Balance Trend: Positive trend of 262,308, slightly above average but lower than Clusters 0 and 2.
Product Holdings:
Revocable Trust: High ownership of Revocable Trusts compared to other clusters.
Private Wealth CD: Strong presence, similar to Cluster 2.
Cluster 8:
Balance Trend: Moderate positive balance trend of 105,297.
Product Holdings:
Unsecured Line: High ownership of Unsecured Line products, not seen much in other clusters.
Cluster 9:
Balances: Very low balance trend (9,097) and low financial activity.
Product Holdings:
Roth IRA and Money Market: Higher ownership in these categories, despite low overall financial activity.
General Observations:
Cluster 0 stands out with the highest positive balance trend and high ownership of Money Market and HELOC products.
Cluster 1 is distinct with a negative balance trend and high ownership of Commercial Line of Credit and Roth IRA products.
Clusters 2 and 7 show significant Private Wealth CD ownership, with Cluster 2 also being highly active in recent product openings.
Cluster 6 is notable for its focus on retirement products like SEP IRA and Traditional IRA.
Cluster 9 has low balance trends but stands out for ownership of Roth IRA and Money Market products.























import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
import numpy as np
import pandas as pd




# Apply PCA to reduce to 3 dimensions
pca_3d = PCA(k=3, inputCol="scaledFeatures", outputCol="pcaFeatures")
pca_model_3d = pca_3d.fit(df_with_clusters)
df_pca_3d = pca_model_3d.transform(df_with_clusters)

# Convert to Pandas for 3D plotting
df_pca_3d_pd = df_pca_3d.select("pcaFeatures", "prediction").toPandas()
df_pca_3d_pd['PCA1'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[0])
df_pca_3d_pd['PCA2'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[1])
df_pca_3d_pd['PCA3'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[2])

# Assuming df_pca_3d_pd is your DataFrame with the 3D PCA features and cluster labels
# Calculate the global x, y, and z limits
x_min = df_pca_3d_pd['PCA1'].min()
x_max = df_pca_3d_pd['PCA1'].max()
y_min = df_pca_3d_pd['PCA2'].min()
y_max = df_pca_3d_pd['PCA2'].max()
z_min = df_pca_3d_pd['PCA3'].min()
z_max = df_pca_3d_pd['PCA3'].max()

# Number of clusters
num_clusters = df_pca_3d_pd['prediction'].nunique()

# Create 3D subplots (adjust rows/cols for number of clusters)
fig = plt.figure(figsize=(14, 12))
axes = []

# Create subplots for each cluster
for i, cluster in enumerate(df_pca_3d_pd['prediction'].unique()):
    ax = fig.add_subplot(num_clusters // 2 + num_clusters % 2, 2, i + 1, projection='3d')
    subset = df_pca_3d_pd[df_pca_3d_pd['prediction'] == cluster]
    
    # Scatter plot for each cluster
    ax.scatter(subset['PCA1'], subset['PCA2'], subset['PCA3'], s=100, alpha=0.7)
    
    # Set title and labels
    ax.set_title(f'Cluster {cluster}')
    ax.set_xlabel('PCA1')
    ax.set_ylabel('PCA2')
    ax.set_zlabel('PCA3')
    
    # Set the same limits for all axes
    ax.set_xlim(x_min, x_max)
    ax.set_ylim(y_min, y_max)
    ax.set_zlim(z_min, z_max)

    axes.append(ax)

# Adjust layout
plt.tight_layout()
plt.show()



from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
import pandas as pd
import numpy as np

# Assuming df_with_clusters is your DataFrame with the features and cluster labels
df_pandas = df_with_clusters.select("scaledFeatures", "prediction").toPandas()

# Extract features and labels
X = np.array(df_pandas["scaledFeatures"].values.tolist())  # Convert the 'scaledFeatures' column to a 2D array
y = df_pandas['prediction']

# Apply t-SNE for dimensionality reduction to 3D
tsne = TSNE(n_components=3, perplexity=30, n_iter=300)
X_tsne = tsne.fit_transform(X)

# Create a DataFrame for plotting
df_tsne = pd.DataFrame(X_tsne, columns=['t-SNE1', 't-SNE2', 't-SNE3'])
df_tsne['cluster'] = y

# Create a 3D plot
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# Create scatter plot
scatter = ax.scatter(df_tsne['t-SNE1'], df_tsne['t-SNE2'], df_tsne['t-SNE3'], 
                     c=df_tsne['cluster'], cmap='Set1', s=100, alpha=0.7)

# Set labels
ax.set_xlabel('t-SNE1')
ax.set_ylabel('t-SNE2')
ax.set_zlabel('t-SNE3')
plt.title("3D t-SNE Cluster Visualization")

# Add a legend
plt.legend(*scatter.legend_elements(), title="Clusters")

# Show the plot
plt.show()

































from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Assuming df_with_clusters is your DataFrame with the features and cluster labels
df_pandas = df_with_clusters.select("scaledFeatures", "prediction").toPandas()

# Extract features and labels
# scaledFeatures contains a list for each row, so you need to convert it to a 2D NumPy array
X = np.array(df_pandas["scaledFeatures"].values.tolist())  # Convert the 'scaledFeatures' column to a 2D array
y = df_pandas['prediction']

# Apply t-SNE for dimensionality reduction to 2D
tsne = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne = tsne.fit_transform(X)

# Create a DataFrame for plotting
df_tsne = pd.DataFrame(X_tsne, columns=['t-SNE1', 't-SNE2'])
df_tsne['cluster'] = y

# Plot t-SNE result
plt.figure(figsize=(10, 7))
sns.scatterplot(x='t-SNE1', y='t-SNE2', hue='cluster', palette='Set1', data=df_tsne, s=100, alpha=0.7)
plt.title("t-SNE Cluster Visualization")
plt.show()


import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Calculate the global x and y limits
x_min = df_pca_pd['PCA1'].min()
x_max = df_pca_pd['PCA1'].max()
y_min = df_pca_pd['PCA2'].min()
y_max = df_pca_pd['PCA2'].max()

# Number of clusters
num_clusters = df_pca_pd['prediction'].nunique()

# Create subplots (rows x cols depending on the number of clusters)
fig, axes = plt.subplots(nrows=num_clusters // 2 + num_clusters % 2, ncols=2, figsize=(14, 12))  # Adjust rows/cols for number of clusters
axes = axes.flatten()  # Flatten the axes array to iterate

# Plot each cluster separately
for i, cluster in enumerate(df_pca_pd['prediction'].unique()):
    subset = df_pca_pd[df_pca_pd['prediction'] == cluster]
    ax = axes[i]  # Get the corresponding axis
    sns.scatterplot(x='PCA1', y='PCA2', data=subset, s=100, alpha=0.7, ax=ax)
    ax.set_title(f'Cluster {cluster}')
    
    # Set the same x and y limits for each plot
    ax.set_xlim(x_min, x_max)
    ax.set_ylim(y_min, y_max)

# Remove any empty subplots if the number of clusters is odd
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

# Adjust layout
plt.tight_layout()
plt.show()





plt.figure(figsize=(10, 7))
sns.scatterplot(x='PCA1', y='PCA2', hue='prediction', palette='Set1', data=df_pca_pd, s=200, alpha=0.5)
plt.title("2D PCA Cluster Visualization with Transparency")
plt.show()

plt.figure(figsize=(14, 12))
for cluster in df_pca_pd['prediction'].unique():
    subset = df_pca_pd[df_pca_pd['prediction'] == cluster]
    plt.scatter(subset['PCA1'], subset['PCA2'], label=f'Cluster {cluster}', s=100, alpha=0.7)

plt.title("Clusters Visualized Separately")
plt.legend()
plt.show()



import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Number of clusters
num_clusters = df_pca_pd['prediction'].nunique()

# Create subplots (rows x cols depending on the number of clusters)
fig, axes = plt.subplots(nrows=num_clusters // 2, ncols=2, figsize=(14, 12))  # Adjust rows/cols for number of clusters
axes = axes.flatten()  # Flatten the axes array to iterate

# Plot each cluster separately
for i, cluster in enumerate(df_pca_pd['prediction'].unique()):
    subset = df_pca_pd[df_pca_pd['prediction'] == cluster]
    ax = axes[i]  # Get the corresponding axis
    sns.scatterplot(x='PCA1', y='PCA2', data=subset, s=100, alpha=0.7, ax=ax)
    ax.set_title(f'Cluster {cluster}')

# Adjust layout
plt.tight_layout()
plt.show()






def perform_clustering(spark, df, features, k):
    """
    Performs K-Means clustering on the PWM data and returns the cluster centers and data with cluster assignments.
    
    Args:
        df (DataFrame): DataFrame containing only PWM client data.
        features (list): List of feature names to include in the clustering.
        k (int): Number of clusters.
        
    Returns:
        centers_df (DataFrame): DataFrame containing cluster centers.
        df_with_clusters (DataFrame): DataFrame with cluster assignments.
    """
    assembler = VectorAssembler(inputCols=features, outputCol="features", handleInvalid="skip")
    scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")
    
    # Pipeline: Assemble features -> Normalize -> Cluster
    kmeans = KMeans(featuresCol="scaledFeatures", k=k, seed=42)
    pipeline = Pipeline(stages=[assembler, scaler, kmeans])
    
    model = pipeline.fit(df)
    
    # Cluster centers
    centers = model.stages[-1].clusterCenters()
    centers_rows = [Row(features=center.tolist()) for center in centers]
    centers_df = spark.createDataFrame(centers_rows)
    
    # Data with cluster assignments
    df_with_clusters = model.transform(df).select("hh_id_in_wh", "scaledFeatures", "prediction")
    
    return centers_df, df_with_clusters


from pyspark.ml.feature import PCA
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Perform clustering and get the data with cluster assignments
centers_df, df_with_clusters = perform_clustering(spark, df, features, k=5)

# Reduce dimensions with PCA (from Spark)
pca = PCA(k=2, inputCol="scaledFeatures", outputCol="pcaFeatures")
pca_model = pca.fit(df_with_clusters)
df_pca = pca_model.transform(df_with_clusters)

# Convert the result to Pandas for plotting
df_pca_pd = df_pca.select("pcaFeatures", "prediction").toPandas()

# Create separate columns for PCA1 and PCA2
df_pca_pd['PCA1'] = df_pca_pd['pcaFeatures'].apply(lambda x: x[0])
df_pca_pd['PCA2'] = df_pca_pd['pcaFeatures'].apply(lambda x: x[1])

# Plot the clusters
plt.figure(figsize=(10, 7))
sns.scatterplot(x='PCA1', y='PCA2', hue='prediction', palette='Set1', data=df_pca_pd, s=100)
plt.title("2D Cluster Visualization (PCA Reduced)")
plt.show()


from mpl_toolkits.mplot3d import Axes3D

# Apply PCA to reduce to 3 dimensions
pca_3d = PCA(k=3, inputCol="scaledFeatures", outputCol="pcaFeatures")
pca_model_3d = pca_3d.fit(df_with_clusters)
df_pca_3d = pca_model_3d.transform(df_with_clusters)

# Convert to Pandas for 3D plotting
df_pca_3d_pd = df_pca_3d.select("pcaFeatures", "prediction").toPandas()
df_pca_3d_pd['PCA1'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[0])
df_pca_3d_pd['PCA2'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[1])
df_pca_3d_pd['PCA3'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[2])

# 3D Scatter plot
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

scatter = ax.scatter(df_pca_3d_pd['PCA1'], df_pca_3d_pd['PCA2'], df_pca_3d_pd['PCA3'], 
                     c=df_pca_3d_pd['prediction'], cmap='Set1')

ax.set_xlabel('PCA1')
ax.set_ylabel('PCA2')
ax.set_zlabel('PCA3')
plt.title("3D Cluster Visualization")

plt.show()





