def perform_clustering(spark, df, features, k):
    """
    Performs K-Means clustering on the PWM data and returns the cluster centers and data with cluster assignments.
    
    Args:
        df (DataFrame): DataFrame containing only PWM client data.
        features (list): List of feature names to include in the clustering.
        k (int): Number of clusters.
        
    Returns:
        centers_df (DataFrame): DataFrame containing cluster centers.
        df_with_clusters (DataFrame): DataFrame with cluster assignments.
    """
    assembler = VectorAssembler(inputCols=features, outputCol="features", handleInvalid="skip")
    scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")
    
    # Pipeline: Assemble features -> Normalize -> Cluster
    kmeans = KMeans(featuresCol="scaledFeatures", k=k, seed=42)
    pipeline = Pipeline(stages=[assembler, scaler, kmeans])
    
    model = pipeline.fit(df)
    
    # Cluster centers
    centers = model.stages[-1].clusterCenters()
    centers_rows = [Row(features=center.tolist()) for center in centers]
    centers_df = spark.createDataFrame(centers_rows)
    
    # Data with cluster assignments
    df_with_clusters = model.transform(df).select("hh_id_in_wh", "scaledFeatures", "prediction")
    
    return centers_df, df_with_clusters


from pyspark.ml.feature import PCA
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Perform clustering and get the data with cluster assignments
centers_df, df_with_clusters = perform_clustering(spark, df, features, k=5)

# Reduce dimensions with PCA (from Spark)
pca = PCA(k=2, inputCol="scaledFeatures", outputCol="pcaFeatures")
pca_model = pca.fit(df_with_clusters)
df_pca = pca_model.transform(df_with_clusters)

# Convert the result to Pandas for plotting
df_pca_pd = df_pca.select("pcaFeatures", "prediction").toPandas()

# Create separate columns for PCA1 and PCA2
df_pca_pd['PCA1'] = df_pca_pd['pcaFeatures'].apply(lambda x: x[0])
df_pca_pd['PCA2'] = df_pca_pd['pcaFeatures'].apply(lambda x: x[1])

# Plot the clusters
plt.figure(figsize=(10, 7))
sns.scatterplot(x='PCA1', y='PCA2', hue='prediction', palette='Set1', data=df_pca_pd, s=100)
plt.title("2D Cluster Visualization (PCA Reduced)")
plt.show()


from mpl_toolkits.mplot3d import Axes3D

# Apply PCA to reduce to 3 dimensions
pca_3d = PCA(k=3, inputCol="scaledFeatures", outputCol="pcaFeatures")
pca_model_3d = pca_3d.fit(df_with_clusters)
df_pca_3d = pca_model_3d.transform(df_with_clusters)

# Convert to Pandas for 3D plotting
df_pca_3d_pd = df_pca_3d.select("pcaFeatures", "prediction").toPandas()
df_pca_3d_pd['PCA1'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[0])
df_pca_3d_pd['PCA2'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[1])
df_pca_3d_pd['PCA3'] = df_pca_3d_pd['pcaFeatures'].apply(lambda x: x[2])

# 3D Scatter plot
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

scatter = ax.scatter(df_pca_3d_pd['PCA1'], df_pca_3d_pd['PCA2'], df_pca_3d_pd['PCA3'], 
                     c=df_pca_3d_pd['prediction'], cmap='Set1')

ax.set_xlabel('PCA1')
ax.set_ylabel('PCA2')
ax.set_zlabel('PCA3')
plt.title("3D Cluster Visualization")

plt.show()


